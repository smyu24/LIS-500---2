<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <title>Interjection Classifier</title>
  <link rel="stylesheet" href="style.css" />
  
  <!-- p5.js + ml5.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/addons/p5.dom.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/addons/p5.sound.min.js"></script>
  <script src="https://unpkg.com/ml5@0.4.2/dist/ml5.min.js"></script>
</head>
<body>

  <!-- Header/Navbar -->
  <header class="header">
    <h1>Accent & Gender Classifier</h1>
    <nav>
      <ul class="menu">
        <li><a href="index.html">Home</a></li>
        <li><a href="machine.html">Our Machine</a></li>
      </ul>
    </nav>
  </header>

  <!-- Main Content -->
  <main class="main">

    <section class="introduction">
      <h2>Welcome to Our Project</h2>
      <p>
        This project focuses on detecting <strong>Accents + Gender</strong> of users in real time using a sound classifier. Creating this model has been an interesting ethical dilemma, and it was especially rewarding to see the accuracy post model tuning
      </p>
      <br>
      <h2>How It Works</h2>
      <p>
        We used <a href="https://teachablemachine.withgoogle.com/" target="_blank">Teachable Machine</a> by Google to train a sound classifier.
        It listens to ~30-second audio clips and compares them to the trained patterns based on pitch, rhythm, and tone.
      </p>
      <p>
        The model was trained with several common accents (total of 8 male & female), and it updates predictions live as you speak.
      </p>
    </section>

    <section class="content">
      <h2>Project Goals</h2>
      <ul class="contenttext">
        <li>Showcase how machine learning can interpret spontaneous human speech patterns.</li>
        <li>Explore emotional nuance in voice and sound.</li>
        <li>Utilize accessible tools like Teachable Machine and p5.js.</li>
        <li>Build a fun, interactive web-based demo.</li>
      </ul>
    <br>
      <h2>Challenges & Learnings</h2>
      <p>
        Interjections are often subtle and vary based on tone and emotion. This made classification tricky—"hmm" could be thoughtful or confused depending on how it’s said.
      </p>
      <p>
        We learned that real-world audio is messy, and creating a responsive model requires a diverse dataset with clear labeling and consistency across voice types.
      </p>
    </section>

    <section class="content">
      <h2>Next Steps</h2>
      <ul class="contenttext">
        <li>Train with more interjection types and real-world background noise.</li>
        <li>Add support for multilingual interjections.</li>
        <li>Combine with emotion recognition models to provide context.</li>
        <li>Test use cases in education, accessibility, and human-computer interaction.</li>
      </ul>

      <div class="contenttext">
          <h2>Explore the Code</h2>
          <p>
            View the source code and dataset information on our GitHub repository: <a href="https://github.com/smyu24/LIS-500---2" target="_blank">GitHub Repository</a><br>
            Dataset was inspired by <a href="https://www.kaggle.com/datasets/rtatman/speech-accent-archive" target="_blank"> https://www.kaggle.com/datasets/rtatman/speech-accent-archive</a> as well as the work conducted by <i>Weinberger, S. (2013). Speech accent archive. George Mason University</i>
          </p>
        </div>
    </section>


    <section class="introduction">
      <h2>Try It Out!</h2>
      <p>
        Research by Prof. Weinberger states the following to be a way to reveal accents: Please call Stella.  Ask her to bring these things with her from the store:  Six spoons of fresh snow peas, five thick slabs of blue cheese, and maybe a snack for her brother Bob.  We also need a small plastic snake and a big toy frog for the kids.  She can scoop these things into three red bags, and we will go meet her Wednesday at the train station. 
        Our classifier will attempt to recognize it instantly.
      </p>
      <script src="model.js"></script>
    </section>
  </main>

</body>
</html>
