<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <title>Accent + Gender Classifier</title>
  <link rel="stylesheet" href="style.css" />
  
  <!-- p5.js + ml5.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/addons/p5.dom.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/addons/p5.sound.min.js"></script>
  <script src="https://unpkg.com/ml5@0.4.2/dist/ml5.min.js"></script>
</head>
<body>

  <!-- Header/Navbar -->
  <header class="header">
    <h1>Accent & Gender Classifier</h1>
    <nav>
      <ul class="menu">
        <li><a href="index.html">Home</a></li>
        <li><a href="machine.html">Our Machine</a></li>
      </ul>
    </nav>
  </header>

  <!-- Main Content -->
  <main class="main">

    <section class="introduction">
      <h2>Welcome to Our Project</h2>
      <p>
        This project focuses on detecting <strong>Accents + Gender</strong> of users in real time using a sound classifier. Creating this model has been an interesting ethical dilemma, and it was especially rewarding to see the accuracy post model tuning
      </p>
      <br>
      <h2>How It Works</h2>
      <p>
        We used <a href="https://teachablemachine.withgoogle.com/" target="_blank">Teachable Machine</a> by Google to train a sound classifier.
        It listens to ~3-second audio clips and compares them to the trained patterns based on pitch, rhythm, and tone.
      </p>
      <p>
        The model was trained with several common accents (total of 8 male & female), and it updates predictions live as you speak.
      </p>
    </section>

    <section class="content">
  <h2>Project Goals</h2>
  <ul class="contenttext">
    <li>Build a voice classifier using Teachable Machine to identify simple spoken words.</li>
    <li>Test model accuracy across speakers with varied accents and voice pitches.</li>
    <li>Critically examine the ethical stakes of accent bias in machine learning systems.</li>
    <li>Engage with ideas from Joy Buolamwini’s <em>Unmasking AI</em> to inform design reflections.</li>
  </ul>
  <br>
  <h2>Challenges & Learnings</h2>
  <p>
    Accent bias in voice models often leads to misclassification, not due to mispronunciation, but because of deviations from the “standard” accent used during training. Participants speaking with Korean, Indian, or Spanish accents were frequently misidentified or not recognized at all.
  </p>
  <p>
    This revealed that models don't truly “listen”—they pattern-match against a narrow dataset. The model, trained on a subset of voices, struggled with others, especially when pitch, intonation, or rhythm varied. This isn’t just technical—it’s cultural. It shows how AI can replicate exclusion if it isn’t designed with diversity in mind.
  </p>
  <p>
    Buolamwini’s concept of the “coded gaze” reminded me that building a classifier is an act of power. The biases in our data reflect who is seen—and who is ignored—by technology.
  </p>
</section>

<section class="content">
  <h2>Does the Model Work?</h2>
  <p>
    While our model performs well under controlled conditions, several factors can affect how reliably it works across different devices and environments. Performance may vary depending on:
  </p>
  <ul class="contenttext">
    <li><strong>Browser compatibility:</strong> The classifier is optimized for modern browsers like Google Chrome. Older or unsupported browsers may not grant microphone access properly or may lag during real-time inference.</li>
    <li><strong>Microphone quality:</strong> Built-in laptop mics or mobile microphones might not capture audio as clearly as external ones, which can lead to misclassifications or non-detection.</li>
    <li><strong>Device performance:</strong> Slower devices may delay model loading or cause glitches in prediction rendering due to limited processing power.</li>
    <li><strong>Network latency:</strong> Because the model is hosted via ml5.js and Teachable Machine, a strong internet connection is necessary to load it efficiently on first use.</li>
  </ul>
  <br>
  <p>
    <strong>False Positives:</strong> While false negatives (i.e., non-detection) are a concern, our model also suffers from false positives—where it assigns incorrect labels. For instance, soft-spoken male voices were occasionally labeled as female, and some tonal overlaps between accents (such as Indian and Middle Eastern) led to misclassification. These errors highlight the model's tendency to rely on pitch and intonation more than the linguistic content itself.
  </p>
  <p>
    <strong>Model Fragility:</strong> Since the classifier updates in real-time every few seconds, it can flicker between categories if there's slight variation in how someone speaks—or due to background noise. This makes the model feel unstable at times and suggests a need for either confidence thresholds or smoothing of predictions to reduce confusion for users.
  </p>
</section>


<section class="content">
  <h2>Next Steps</h2>
  <ul class="contenttext">
    <li>Expand the dataset with a broader range of voices, accents, and pitches.</li>
    <li>Integrate background noise and real-world conditions into training environments.</li>
    <li>Explore multilingual input and dialect-sensitive classification approaches.</li>
    <li>Frame the project as an interactive critique of AI bias in public exhibitions or educational settings.</li>
    <li>Continue reflecting on ethical AI design, centering inclusion over efficiency.</li>
  </ul>

      <div class="contenttext">
          <h2>Explore the Code</h2>
          <p>
            View the source code and dataset information on our GitHub repository: <a href="https://github.com/smyu24/LIS-500---2" target="_blank">GitHub Repository</a><br>
            Dataset was inspired by <a href="https://www.kaggle.com/datasets/rtatman/speech-accent-archive" target="_blank"> https://www.kaggle.com/datasets/rtatman/speech-accent-archive</a> as well as the work conducted by <i>Weinberger, S. (2013). Speech accent archive. George Mason University</i>
          </p>
        </div>
    </section>


    <section class="introduction">
  <h2>Try It Out!</h2>
  <p>
    Research by Prof. Weinberger states the following to be a way to reveal accents: 
    <u>
      Please call Stella. Ask her to bring these things with her from the store: Six spoons of fresh snow peas, five thick slabs of blue cheese, and maybe a snack for her brother Bob. 
      We also need a small plastic snake and a big toy frog for the kids. She can scoop these things into three red bags, and we will go meet her Wednesday at the train station.
    </u>
    <br>
    Our classifier will attempt to recognize it instantly.
  </p>

  <!-- Classifier Container -->
  <script src="model.js"></script>
</section>
  </main>

</body>
</html>
